{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data point-to-point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "data1 = pd.read_csv(\"2016-usopen-points.csv\")\n",
    "data2 = pd.read_csv(\"2016-wimbledon-points.csv\")\n",
    "data3 = pd.read_csv(\"2017-usopen-points.csv\")\n",
    "data4 = pd.read_csv(\"2017-wimbledon-points.csv\")\n",
    "data5 = pd.read_csv(\"2018-usopen-points.csv\")\n",
    "data6 = pd.read_csv(\"2018-wimbledon-points.csv\")\n",
    "data7 = pd.read_csv(\"2019-usopen-points.csv\")\n",
    "data8 = pd.read_csv(\"2019-wimbledon-points.csv\")\n",
    "data9 = pd.read_csv(\"2020-usopen-points.csv\")\n",
    "\n",
    "dataSamlet = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9])\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None, \"display.max_rows\", 300)\n",
    "dataSamlet = dataSamlet.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hala = dataSamlet.loc[dataSamlet['P1DistanceRun'] != 0] #Finds all match_id's with values of ServeWidth, ServeDepth and ReturnDepth\n",
    "\n",
    "df = pd.DataFrame(columns=hala.columns) #Making empty dataframe\n",
    "\n",
    "for i in range(len(hala.match_id.unique())): #Adding matches which have values in ServeWidth, ServeDepth and ReturnDepth\n",
    "    \n",
    "    df = df.append(dataSamlet.loc[dataSamlet['match_id'] == hala.match_id.unique()[i]])\n",
    "\n",
    "df = df.reset_index(drop=True) #Reset index\n",
    "\n",
    "for i in range(len(df)): #Making return balls which the opponent smash on have a ReturnDepth and not NaN\n",
    "    \n",
    "    if pd.isna(df.iloc[i]['ReturnDepth']) and df.iloc[i]['RallyCount'] > 1:\n",
    "        df['ReturnDepth'][i] = 'Service box'\n",
    "        \n",
    "for i in range(len(df)): #Giving rows with double fault a value for ServeWidth, ServeDepth and ReturnDepth\n",
    "    \n",
    "    if df.iloc[i]['P1DoubleFault'] == 1 or df.iloc[i]['P2DoubleFault'] == 1:\n",
    "        df['ServeWidth'][i] = 'DoubleFault'\n",
    "        df['ServeDepth'][i] = 'DoubleFault'\n",
    "        df['ReturnDepth'][i] = 'DoubleFault'\n",
    "        \n",
    "for i in range(len(df)): #Giving rows with WinnerType S a P1Ace or P2Ace\n",
    "    \n",
    "    if (df.iloc[i]['WinnerType'] == 'S' and df.iloc[i]['PointServer'] == 1):\n",
    "        df['P1Ace'][i] = 1\n",
    "        \n",
    "    elif (df.iloc[i]['WinnerType'] == 'S' and df.iloc[i]['PointServer'] == 2):\n",
    "        df['P2Ace'][i] = 1\n",
    "    \n",
    "for i in range(len(df)): #An Ace and a serve where the opponent touches it but it doesnt hit the field have the same value.\n",
    "    \n",
    "    if df.iloc[i]['RallyCount'] <= 1 and pd.isna(df.iloc[i]['ReturnDepth']) and df.iloc[i]['PointServer'] == 1:\n",
    "        df['P1Ace'][i] = 1\n",
    "        \n",
    "    elif df.iloc[i]['RallyCount'] <= 1 and pd.isna(df.iloc[i]['ReturnDepth']) and df.iloc[i]['PointServer'] == 2:\n",
    "        df['P2Ace'][i] = 1\n",
    "\n",
    "        \n",
    "for i in range(len(df)): #Making serve aces point a ReturnDepth\n",
    "    \n",
    "    if df.iloc[i]['P1Ace'] == 1 or df.iloc[i]['P2Ace'] == 1:\n",
    "        df['ReturnDepth'][i] = 'ServeAce'\n",
    "        \n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)): #Making start row for each match with P1Score = 0, P2Score = 0 and PointNumber = 0\n",
    "    \n",
    "    if df.iloc[i]['PointNumber'] == '0X':\n",
    "        \n",
    "        df = df.drop(i)\n",
    "        df['PointNumber'][i+1] = '0'\n",
    "        df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forskyd = df1[['ElapsedTime','SetNo','SetWinner','GameNo','GameWinner','PointNumber','PointWinner','PointServer','Speed_KMH','P1Momentum','P2Momentum','P1Ace','P2Ace','P1Winner','P2Winner','P1DoubleFault','P2DoubleFault','P1UnfErr','P2UnfErr','P1NetPoint','P2NetPoint','P1BreakPoint','P2BreakPoint','History','Speed_MPH','ServeIndicator','ServeNumber','WinnerType','WinnerShotType','P1DistanceRun','P2DistanceRun','RallyCount','ServeWidth','ServeDepth','ReturnDepth']].to_numpy()\n",
    "\n",
    "a = Forskyd[0]\n",
    "\n",
    "Forskyd = np.delete(Forskyd, 0, 0)\n",
    "\n",
    "Forskyd = np.vstack([Forskyd, a])\n",
    "\n",
    "df1[['ElapsedTime','SetNo','SetWinner','GameNo','GameWinner','PointNumber','PointWinner','PointServer','Speed_KMH','P1Momentum','P2Momentum','P1Ace','P2Ace','P1Winner','P2Winner','P1DoubleFault','P2DoubleFault','P1UnfErr','P2UnfErr','P1NetPoint','P2NetPoint','P1BreakPoint','P2BreakPoint','History','Speed_MPH','ServeIndicator','ServeNumber','WinnerType','WinnerShotType','P1DistanceRun','P2DistanceRun','RallyCount','ServeWidth','ServeDepth','ReturnDepth']] = Forskyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.PointNumber != 0]\n",
    "df1 = df1[df1.PointNumber != '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making accumulated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.drop(df[[\"P1Momentum\", \"P2Momentum\", \"Speed_MPH\",\"History\"]], axis=1)\n",
    "df = df[df.ElapsedTime != \"0\"]\n",
    "\n",
    "bad_id=[]\n",
    "id=np.unique(df['match_id'].to_numpy())\n",
    "\n",
    "for i in range(len(id)):\n",
    "    if id[i][-4]==\"2\":\n",
    "        bad_id.append(id[i])\n",
    "\n",
    "df=df[df[\"match_id\"].apply(lambda x:x not in bad_id)]\n",
    "\n",
    "df.P1Score = df.P1Score.replace({\"AD\": 50})\n",
    "df.P2Score = df.P2Score.replace({\"AD\": 50})\n",
    "cols=['PointNumber','P1Score', 'P2Score']\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df = df[df.match_id != \"2018-wimbledon-1306\"]\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['ElapsedTime'], format='%H:%M:%S')\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "time_sec=[]\n",
    "for i in range(len(df)-1):\n",
    "    time_sec.append((df['datetime'].iloc[i+1]-df['datetime'][i]).total_seconds())\n",
    "time_sec.append(-1234)\n",
    "\n",
    "df['Point_lenght_sec']=time_sec\n",
    "\n",
    "df_A=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_ServeWidth=[]\n",
    "P1_ServeDepth=[]\n",
    "P1_ReturnDepth=[]\n",
    "P2_ServeWidth=[]\n",
    "P2_ServeDepth=[]\n",
    "P2_ReturnDepth=[]\n",
    "\n",
    "cols=['P1_ServeWidth','P1_ServeDepth','P1_ReturnDepth','P2_ServeWidth','P2_ServeDepth','P2_ReturnDepth']\n",
    "\n",
    "for i in range(len(df_A.match_id.unique())):\n",
    "        b = df[df['match_id'] == df.match_id.unique()[i]]\n",
    "        Width=0\n",
    "        Depth=0\n",
    "        Return=0\n",
    "        for j in b.index:\n",
    "            if b.PointServer[j] == 1:\n",
    "                P1_ServeWidth.append(b.ServeWidth[j])\n",
    "                P1_ServeDepth.append(b.ServeDepth[j])\n",
    "                P1_ReturnDepth.append(b.ReturnDepth[j])\n",
    "                P2_ServeWidth.append(0)\n",
    "                P2_ServeDepth.append(0)\n",
    "                P2_ReturnDepth.append(0)\n",
    "\n",
    "            elif b.PointServer[j] == 2:\n",
    "                P2_ServeWidth.append(b.ServeWidth[j])\n",
    "                P2_ServeDepth.append(b.ServeDepth[j])\n",
    "                P2_ReturnDepth.append(b.ReturnDepth[j])\n",
    "                P1_ServeWidth.append(0)\n",
    "                P1_ServeDepth.append(0)\n",
    "                P1_ReturnDepth.append(0)\n",
    "            else:\n",
    "                P2_ServeWidth.append(0)\n",
    "                P2_ServeDepth.append(0)\n",
    "                P2_ReturnDepth.append(0)\n",
    "                P1_ServeWidth.append(0)\n",
    "                P1_ServeDepth.append(0)\n",
    "                P1_ReturnDepth.append(0)\n",
    "\n",
    "\n",
    "df_A['P1_ServeWidth']=P1_ServeWidth\n",
    "df_A['P1_ServeDepth']=P1_ServeDepth\n",
    "df_A['P1_ReturnDepth']=P1_ReturnDepth\n",
    "df_A['P2_ServeWidth']=P2_ServeWidth\n",
    "df_A['P2_ServeDepth']=P2_ServeDepth\n",
    "df_A['P2_ReturnDepth']=P2_ReturnDepth\n",
    "\n",
    "\n",
    "\n",
    "output = [x for x in pd.get_dummies(df_A,columns=cols).columns if not x in df_A.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A=pd.get_dummies(df_A,columns=cols)\n",
    "\n",
    "P1_ServeWidth_B_A =[]\n",
    "P1_ServeWidth_BC_A =[]\n",
    "P1_ServeWidth_BW_A =[]\n",
    "P1_ServeWidth_C_A =[]\n",
    "P1_ServeWidth_DoubleFault_A =[]\n",
    "P1_ServeWidth_W_A =[]\n",
    "P1_ServeDepth_CTL_A =[]\n",
    "P1_ServeDepth_DoubleFault_A =[]\n",
    "P1_ServeDepth_NCTL_A =[]\n",
    "P1_ReturnDepth_D_A =[]\n",
    "P1_ReturnDepth_DoubleFault_A =[]\n",
    "P1_ReturnDepth_ND_A =[]\n",
    "P1_ReturnDepth_ServeAce_A =[]\n",
    "P1_ReturnDepth_Service_box_A =[]\n",
    "P2_ServeWidth_B_A =[]\n",
    "P2_ServeWidth_BC_A =[]\n",
    "P2_ServeWidth_BW_A =[]\n",
    "P2_ServeWidth_C_A =[]\n",
    "P2_ServeWidth_DoubleFault_A =[]\n",
    "P2_ServeWidth_W_A =[]\n",
    "P2_ServeDepth_CTL_A =[]\n",
    "P2_ServeDepth_DoubleFault_A =[]\n",
    "P2_ServeDepth_NCTL_A =[]\n",
    "P2_ReturnDepth_D_A =[]\n",
    "P2_ReturnDepth_DoubleFault_A =[]\n",
    "P2_ReturnDepth_ND_A =[]\n",
    "P2_ReturnDepth_ServeAce_A =[]\n",
    "P2_ReturnDepth_Service_box_A =[]\n",
    "\n",
    "\n",
    "for i in range(len(df.match_id.unique())):\n",
    "    P1_ServeWidth_B_A = np.append(P1_ServeWidth_B_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_B.cumsum().values[:-1],0,0))\n",
    "    P1_ServeWidth_BC_A = np.append(P1_ServeWidth_BC_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_BC.cumsum().values[:-1],0,0))\n",
    "    P1_ServeWidth_BW_A = np.append(P1_ServeWidth_BW_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_BW.cumsum().values[:-1],0,0))\n",
    "    P1_ServeWidth_C_A = np.append(P1_ServeWidth_C_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_C.cumsum().values[:-1],0,0))\n",
    "    P1_ServeWidth_DoubleFault_A = np.append(P1_ServeWidth_DoubleFault_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P1_ServeWidth_W_A = np.append(P1_ServeWidth_W_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeWidth_W.cumsum().values[:-1],0,0))\n",
    "    P1_ServeDepth_CTL_A = np.append(P1_ServeDepth_CTL_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeDepth_CTL.cumsum().values[:-1],0,0))\n",
    "    P1_ServeDepth_DoubleFault_A = np.append(P1_ServeDepth_DoubleFault_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeDepth_DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P1_ServeDepth_NCTL_A = np.append(P1_ServeDepth_NCTL_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ServeDepth_NCTL.cumsum().values[:-1],0,0))\n",
    "    P1_ReturnDepth_D_A = np.append(P1_ReturnDepth_D_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ReturnDepth_D.cumsum().values[:-1],0,0))\n",
    "  #P1_ReturnDepth_DoubleFault_A = np.append(P1_ReturnDepth_DoubleFault_A, df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ReturnDepth_DoubleFault.cumsum().values)\n",
    "    P1_ReturnDepth_ND_A = np.append(P1_ReturnDepth_ND_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ReturnDepth_ND.cumsum().values[:-1],0,0))\n",
    "    P1_ReturnDepth_ServeAce_A = np.append(P1_ReturnDepth_ServeAce_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ReturnDepth_ServeAce.cumsum().values[:-1],0,0))\n",
    "  #P1_ReturnDepth_Service_box_A = np.append(P1_ReturnDepth_Service_box_A, df_A[df_A['match_id'] == df.match_id.unique()[i]].P1_ReturnDepth_Service_box.cumsum().values)\n",
    "    P2_ServeWidth_B_A = np.append(P2_ServeWidth_B_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_B.cumsum().values[:-1],0,0))\n",
    "    P2_ServeWidth_BC_A = np.append(P2_ServeWidth_BC_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_BC.cumsum().values[:-1],0,0))\n",
    "    P2_ServeWidth_BW_A = np.append(P2_ServeWidth_BW_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_BW.cumsum().values[:-1],0,0))\n",
    "    P2_ServeWidth_C_A = np.append(P2_ServeWidth_C_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_C.cumsum().values[:-1],0,0))\n",
    "    P2_ServeWidth_DoubleFault_A = np.append(P2_ServeWidth_DoubleFault_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P2_ServeWidth_W_A = np.append(P2_ServeWidth_W_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeWidth_W.cumsum().values[:-1],0,0))\n",
    "    P2_ServeDepth_CTL_A = np.append(P2_ServeDepth_CTL_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeDepth_CTL.cumsum().values[:-1],0,0))\n",
    "    P2_ServeDepth_DoubleFault_A = np.append(P2_ServeDepth_DoubleFault_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeDepth_DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P2_ServeDepth_NCTL_A = np.append(P2_ServeDepth_NCTL_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ServeDepth_NCTL.cumsum().values[:-1],0,0))\n",
    "    P2_ReturnDepth_D_A = np.append(P2_ReturnDepth_D_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ReturnDepth_D.cumsum().values[:-1],0,0))\n",
    "  #P2_ReturnDepth_DoubleFault_A = np.append(P2_ReturnDepth_DoubleFault_A, df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ReturnDepth_DoubleFault.cumsum().values)\n",
    "    P2_ReturnDepth_ND_A = np.append(P2_ReturnDepth_ND_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ReturnDepth_ND.cumsum().values[:-1],0,0))\n",
    "    P2_ReturnDepth_ServeAce_A = np.append(P2_ReturnDepth_ServeAce_A, np.insert(df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ReturnDepth_ServeAce.cumsum().values[:-1],0,0))\n",
    "  #P2_ReturnDepth_Service_box_A = np.append(P2_ReturnDepth_Service_box_A, df_A[df_A['match_id'] == df.match_id.unique()[i]].P2_ReturnDepth_Service_box.cumsum().values)\n",
    "\n",
    "df_A['P1_ServeWidth_B_A'] = P1_ServeWidth_B_A\n",
    "df_A['P1_ServeWidth_BC_A'] = P1_ServeWidth_BC_A\n",
    "df_A['P1_ServeWidth_BW_A'] = P1_ServeWidth_BW_A\n",
    "df_A['P1_ServeWidth_C_A'] = P1_ServeWidth_C_A\n",
    "df_A['P1_ServeWidth_DoubleFault_A'] = P1_ServeWidth_DoubleFault_A\n",
    "df_A['P1_ServeWidth_W_A'] = P1_ServeWidth_W_A\n",
    "df_A['P1_ServeDepth_CTL_A'] = P1_ServeDepth_CTL_A\n",
    "df_A['P1_ServeDepth_DoubleFault_A'] = P1_ServeDepth_DoubleFault_A\n",
    "df_A['P1_ServeDepth_NCTL_A'] = P1_ServeDepth_NCTL_A\n",
    "df_A['P1_ReturnDepth_D_A'] = P1_ReturnDepth_D_A\n",
    "#df_A['P1_ReturnDepth_DoubleFault_A'] = P1_ReturnDepth_DoubleFault_A\n",
    "df_A['P1_ReturnDepth_ND_A'] = P1_ReturnDepth_ND_A\n",
    "df_A['P1_ReturnDepth_ServeAce_A'] = P1_ReturnDepth_ServeAce_A\n",
    "#df_A['P1_ReturnDepth_Service_box_A'] = P1_ReturnDepth_Service_box_A\n",
    "df_A['P2_ServeWidth_B_A'] = P2_ServeWidth_B_A\n",
    "df_A['P2_ServeWidth_BC_A'] = P2_ServeWidth_BC_A\n",
    "df_A['P2_ServeWidth_BW_A'] = P2_ServeWidth_BW_A\n",
    "df_A['P2_ServeWidth_C_A'] = P2_ServeWidth_C_A\n",
    "df_A['P2_ServeWidth_DoubleFault_A'] = P2_ServeWidth_DoubleFault_A\n",
    "df_A['P2_ServeWidth_W_A'] = P2_ServeWidth_W_A\n",
    "df_A['P2_ServeDepth_CTL_A'] = P2_ServeDepth_CTL_A\n",
    "df_A['P2_ServeDepth_DoubleFault_A'] = P2_ServeDepth_DoubleFault_A\n",
    "df_A['P2_ServeDepth_NCTL_A'] = P2_ServeDepth_NCTL_A\n",
    "df_A['P2_ReturnDepth_D_A'] = P2_ReturnDepth_D_A\n",
    "#df_A['P2_ReturnDepth_DoubleFault_A'] = P2_ReturnDepth_DoubleFault_A\n",
    "df_A['P2_ReturnDepth_ND_A'] = P2_ReturnDepth_ND_A\n",
    "df_A['P2_ReturnDepth_ServeAce_A'] = P2_ReturnDepth_ServeAce_A\n",
    "#df_A['P2_ReturnDepth_Service_box_A'] = P2_ReturnDepth_Service_box_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1AceA = []\n",
    "P2AceA = []\n",
    "P1WinnerA = []\n",
    "P2WinnerA = []\n",
    "P1DoubleFaultA = []\n",
    "P2DoubleFaultA = []\n",
    "P1UnfErrA = []\n",
    "P2UnfErrA = []\n",
    "P1NetPointA = []\n",
    "P2NetPointA = []\n",
    "P1NetPointWonA = []\n",
    "P2NetPointWonA = []\n",
    "P1BreakPointA = []\n",
    "P2BreakPointA = []\n",
    "P1BreakPointWonA = []\n",
    "P2BreakPointWonA = []\n",
    "P1BreakPointMissedA = []\n",
    "P2BreakPointMissedA = []\n",
    "P1DistanceRunA = []\n",
    "P2DistanceRunA = []\n",
    "RallyCountA = []\n",
    "Avg_Speed_KMH = []\n",
    "P1SetsWon=[]\n",
    "P2SetsWon=[]\n",
    "P1Momentum = []\n",
    "P2Momentum = []\n",
    "\n",
    "for i in range(len(df.match_id.unique())):\n",
    "    #print(f' i is {i}')\n",
    "    P1AceA = np.append(P1AceA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1Ace.cumsum().values[:-1],0,0))\n",
    "    P2AceA = np.append(P2AceA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2Ace.cumsum().values[:-1],0,0))\n",
    "    P1WinnerA = np.append(P1WinnerA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1Winner.cumsum().values[:-1],0,0))\n",
    "    P2WinnerA = np.append(P2WinnerA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2Winner.cumsum().values[:-1],0,0))\n",
    "    P1DoubleFaultA = np.append(P1DoubleFaultA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P2DoubleFaultA = np.append(P2DoubleFaultA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2DoubleFault.cumsum().values[:-1],0,0))\n",
    "    P1UnfErrA = np.append(P1UnfErrA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1UnfErr.cumsum().values[:-1],0,0))\n",
    "    P2UnfErrA = np.append(P2UnfErrA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2UnfErr.cumsum().values[:-1],0,0))\n",
    "    P1NetPointA = np.append(P1NetPointA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1NetPoint.cumsum().values[:-1],0,0))\n",
    "    P2NetPointA = np.append(P2NetPointA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2NetPoint.cumsum().values[:-1],0,0))\n",
    "    P1NetPointWonA = np.append(P1NetPointWonA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1NetPointWon.cumsum().values[:-1],0,0))\n",
    "    P2NetPointWonA = np.append(P2NetPointWonA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2NetPointWon.cumsum().values[:-1],0,0))\n",
    "    P1BreakPointA = np.append(P1BreakPointA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1BreakPoint.cumsum().values[:-1],0,0))\n",
    "    P2BreakPointA = np.append(P2BreakPointA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2BreakPoint.cumsum().values[:-1],0,0))\n",
    "    P1BreakPointWonA = np.append(P1BreakPointWonA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1BreakPointWon.cumsum().values[:-1],0,0))\n",
    "    P2BreakPointWonA = np.append(P2BreakPointWonA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2BreakPointWon.cumsum().values[:-1],0,0))\n",
    "    P1BreakPointMissedA = np.append(P1BreakPointMissedA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1BreakPointMissed.cumsum().values[:-1],0,0))\n",
    "    P2BreakPointMissedA = np.append(P2BreakPointMissedA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2BreakPointMissed.cumsum().values[:-1],0,0))\n",
    "    P1DistanceRunA = np.append(P1DistanceRunA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P1DistanceRun.cumsum().values[:-1],0,0))\n",
    "    P2DistanceRunA = np.append(P2DistanceRunA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].P2DistanceRun.cumsum().values[:-1],0,0))\n",
    "    RallyCountA = np.append(RallyCountA, np.insert(df[df['match_id'] == df.match_id.unique()[i]].RallyCount.cumsum().values[:-1],0,0))\n",
    "\n",
    "\n",
    "    b = df[df['match_id'] == df.match_id.unique()[i]]\n",
    "    P1SetsWonM = []\n",
    "    P2SetsWonM = []\n",
    "    P1MomentumM = []\n",
    "    P2MomentumM = []\n",
    "    P1 = 0\n",
    "    P2 = 0\n",
    "    P1M = 0\n",
    "    P2M = 0\n",
    "    for j in b.index:\n",
    "        #print(f' j is {j}')\n",
    "\n",
    "        if b.SetWinner[j] == 1:\n",
    "            P1 = P1 + 1\n",
    "            \n",
    "        elif b.SetWinner[j] == 2:\n",
    "            P2 = P2 + 1\n",
    "            \n",
    "        elif b.PointWinner[j] == 1:\n",
    "            P1M = P1M + 1\n",
    "            P2M = 0\n",
    "            \n",
    "        elif b.PointWinner[j] == 2:\n",
    "            P2M = P2M + 1\n",
    "            P1M = 0\n",
    "        \n",
    "        P1SetsWonM = np.append(P1SetsWonM, P1)\n",
    "        P2SetsWonM = np.append(P2SetsWonM, P2)\n",
    "        P1MomentumM = np.append(P1MomentumM, P1M)\n",
    "        P2MomentumM = np.append(P2MomentumM, P2M)\n",
    "    \n",
    "    P1SetsWon = np.append(P1SetsWon, np.insert(P1SetsWonM[:-1],0,0))\n",
    "    P2SetsWon = np.append(P2SetsWon, np.insert(P2SetsWonM[:-1],0,0))\n",
    "    P1Momentum = np.append(P1Momentum, np.insert(P1MomentumM[:-1],0,0))\n",
    "    P2Momentum = np.append(P2Momentum, np.insert(P2MomentumM[:-1],0,0))\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "df_A['P1AceA'] = P1AceA\n",
    "df_A['P2AceA'] = P2AceA\n",
    "df_A['P1WinnerA'] = P1WinnerA\n",
    "df_A['P2WinnerA'] = P2WinnerA\n",
    "df_A['P1DoubleFaultA'] = P1DoubleFaultA\n",
    "df_A['P2DoubleFaultA'] = P2DoubleFaultA\n",
    "df_A['P1UnfErrA'] = P1UnfErrA\n",
    "df_A['P2UnfErrA'] = P2UnfErrA\n",
    "df_A['P1NetPointA'] = P1NetPointA\n",
    "df_A['P2NetPointA'] = P2NetPointA\n",
    "df_A['P1NetPointWonA'] = P1NetPointWonA\n",
    "df_A['P2NetPointWonA'] = P2NetPointWonA\n",
    "df_A['P1BreakPointA'] = P1BreakPointA\n",
    "df_A['P2BreakPointA'] = P2BreakPointA\n",
    "df_A['P1BreakPointWonA'] = P1BreakPointWonA\n",
    "df_A['P2BreakPointWonA'] = P2BreakPointWonA\n",
    "df_A['P1BreakPointMissedA'] = P1BreakPointMissedA\n",
    "df_A['P2BreakPointMissedA'] = P2BreakPointMissedA\n",
    "df_A['P1DistanceRunA'] = P1DistanceRunA\n",
    "df_A['P2DistanceRunA'] = P2DistanceRunA\n",
    "df_A['RallyCountA'] = RallyCountA\n",
    "df_A['P1SetsWon'] = P1SetsWon\n",
    "df_A['P2SetsWon'] = P2SetsWon\n",
    "df_A['P1Momentum'] = P1Momentum\n",
    "df_A['P2Momentum'] = P2Momentum\n",
    "\n",
    "set_value=[]\n",
    "game_value=[]\n",
    "for i in range(l A)-1, 0, -1):\n",
    "    if df_A.SetWinner.iloc[i]==0:\n",
    "        set_value.append(set_value[-1])\n",
    "        \n",
    "    if df_A.SetWinner.iloc[i]!=0:\n",
    "        set_value.append(df_A.SetWinner.iloc[i])\n",
    "        \n",
    "    if df_A.GameWinner.iloc[i]==0:\n",
    "        game_value.append(game_value[-1])\n",
    "                          \n",
    "    if df_A.GameWinner.iloc[i]!=0:\n",
    "        game_value.append(df_A.GameWinner.iloc[i])\n",
    "\n",
    "game_value = game_value[::-1]\n",
    "game_value.insert(1,1)\n",
    "#game_value.insert(1,1)\n",
    "\n",
    "set_value = set_value[::-1]\n",
    "set_value.insert(1,1)\n",
    "#set_value.insert(1,1)        \n",
    "\n",
    "df_A['GameWinnerA'] = game_value\n",
    "df_A['SetWinnerA'] = set_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.loc[df['Point_lenght_sec'] < 0, 'Point_lenght_sec'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding player rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data match_atp\n",
    "match2 = pd.read_csv(\"2016-usopen-matches.csv\")\n",
    "match1 = pd.read_csv(\"2016-wimbledon-matches.csv\")\n",
    "match4 = pd.read_csv(\"2017-usopen-matches.csv\")\n",
    "match3 = pd.read_csv(\"2017-wimbledon-matches.csv\")\n",
    "match6 = pd.read_csv(\"2018-usopen-matches.csv\")\n",
    "match5 = pd.read_csv(\"2018-wimbledon-matches.csv\")\n",
    "match8 = pd.read_csv(\"2019-usopen-matches.csv\")\n",
    "match7 = pd.read_csv(\"2019-wimbledon-matches.csv\")\n",
    "match9 = pd.read_csv(\"2020-usopen-matches.csv\")\n",
    "\n",
    "matchSamlet = pd.concat([match1,match2,match3,match4,match5,match6,match7,match8,match9])\n",
    "\n",
    "rank1 = pd.read_csv(\"atp_matches_2016.csv\")\n",
    "rank2 = pd.read_csv(\"atp_matches_2017.csv\")\n",
    "rank3 = pd.read_csv(\"atp_matches_2018.csv\")\n",
    "rank4 = pd.read_csv(\"atp_matches_2019.csv\")\n",
    "rank5 = pd.read_csv(\"atp_matches_2020.csv\")\n",
    "\n",
    "rankSamlet = pd.concat([rank1,rank2,rank3,rank4,rank5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_id=[]\n",
    "id=np.unique(matchSamlet['match_id'].to_numpy())\n",
    "\n",
    "for i in range(len(id)):\n",
    "    if id[i][-4]==\"2\":\n",
    "        bad_id.append(id[i])\n",
    "\n",
    "matchSamlet=matchSamlet[matchSamlet[\"match_id\"].apply(lambda x:x not in bad_id)]\n",
    "\n",
    "matchSamlet = matchSamlet[matchSamlet.match_id != \"2018-wimbledon-1306\"]\n",
    "\n",
    "matchSamlet = matchSamlet.drop(matchSamlet[['status','winner','event_name','round','court_name','court_id','player1id','player2id','nation1','nation2']], axis=1)\n",
    "\n",
    "matchSamlet.slam = matchSamlet.slam.replace({\"wimbledon\": 'Wimbledon'})\n",
    "matchSamlet.slam = matchSamlet.slam.replace({\"usopen\": 'US Open'})\n",
    "\n",
    "matchSamlet.player1 = matchSamlet.player1.replace({'Juan Martin del Potro': 'Juan Martin Del Potro'})\n",
    "matchSamlet.player2 = matchSamlet.player2.replace({'Juan Martin del Potro': 'Juan Martin Del Potro'})\n",
    "matchSamlet.player1 = matchSamlet.player1.replace({'Alex de Minaur': 'Alex De Minaur'})\n",
    "matchSamlet.player2 = matchSamlet.player2.replace({'Alex de Minaur': 'Alex De Minaur'})\n",
    "\n",
    "matchSamlet = matchSamlet.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankSamlet = rankSamlet.drop(rankSamlet[['tourney_id','draw_size','tourney_level', 'winner_entry',\n",
    "                                          'winner_id','winner_seed','winner_ht','winner_ioc','winner_age','loser_id',\n",
    "                                          'loser_seed','loser_entry','loser_ht','loser_ioc','loser_age','score','best_of',\n",
    "                                          'round','minutes','w_ace','w_df','w_svpt','w_1stIn','w_1stWon','w_2ndWon','w_SvGms',\n",
    "                                          'w_bpSaved','w_bpFaced','l_ace','l_df','l_svpt','l_1stIn','l_1stWon','l_2ndWon',\n",
    "                                          'l_SvGms','l_bpSaved','l_bpFaced','winner_rank_points','loser_rank_points']], axis=1)\n",
    "\n",
    "rankSamlet.tourney_name = rankSamlet.tourney_name.replace({\"Us Open\": 'US Open'})\n",
    "\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Jo-Wilfried Tsonga': 'Jo Wilfried Tsonga'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Jo-Wilfried Tsonga': 'Jo Wilfried Tsonga'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Juan Martin del Potro': 'Juan Martin Del Potro'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Juan Martin del Potro': 'Juan Martin Del Potro'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Albert Ramos': 'Albert Ramos Vinolas'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Albert Ramos': 'Albert Ramos Vinolas'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Alex de Minaur': 'Alex De Minaur'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Alex de Minaur': 'Alex De Minaur'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Jc Aragone': 'JC Aragone'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Jc Aragone': 'JC Aragone'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Soon Woo Kwon': 'Soonwoo Kwon'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Soon Woo Kwon': 'Soonwoo Kwon'})\n",
    "rankSamlet.winner_name = rankSamlet.winner_name.replace({'Christian Garin': 'Cristian Garin'})\n",
    "rankSamlet.loser_name = rankSamlet.loser_name.replace({'Christian Garin': 'Cristian Garin'})\n",
    "\n",
    "rankSamlet = rankSamlet[(rankSamlet.tourney_name == 'Wimbledon') | (rankSamlet.tourney_name == 'US Open')]\n",
    "\n",
    "rankSamlet = rankSamlet.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matchSamlet)):\n",
    "    \n",
    "    if 100 < matchSamlet.match_num[i] < 1200:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1001\n",
    "    \n",
    "    if 1200 < matchSamlet.match_num[i] < 1300:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1037\n",
    "        \n",
    "    if 1300 < matchSamlet.match_num[i] < 1400:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1105\n",
    "        \n",
    "    if 1400 < matchSamlet.match_num[i] < 1500:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1189\n",
    "        \n",
    "    if 1500 < matchSamlet.match_num[i] < 1600:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1281\n",
    "    \n",
    "    if 1600 < matchSamlet.match_num[i] < 1700:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1377\n",
    "    \n",
    "    if 1700 < matchSamlet.match_num[i] < 1800:\n",
    "        matchSamlet['match_num'][i] =  matchSamlet['match_num'][i] - 1475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(matchSamlet,rankSamlet, left_on='match_num', right_on='match_num',how='left')\n",
    "a = a.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slettet = []\n",
    "for i in range(len(a)):\n",
    "    if (a.player1[i] == a.winner_name[i] and a.player2[i] == a.loser_name[i] and a.slam[i] == a.tourney_name[i]) or (a.player2[i] == a.winner_name[i] and a.player1[i] == a.loser_name[i] and a.slam[i] == a.tourney_name[i]):\n",
    "        continue\n",
    "    else:\n",
    "        #print(a.match_id[i])\n",
    "        #a = a.drop([i])\n",
    "        slettet.append(i)\n",
    "        \n",
    "a = a.drop(slettet)\n",
    "        \n",
    "a = a.reset_index(drop=True)\n",
    "\n",
    "a = a.drop([384,811,927])#Bad data\n",
    "\n",
    "a = a.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_PR = pd.merge(df_A,a,left_on='match_id',right_on='match_id',how='left')\n",
    "df_A_PR = df_A_PR[df_A_PR.match_id != \"2017-usopen-1303\"]\n",
    "df_A_PR = df_A_PR[df_A_PR.match_id != \"2020-usopen-1149\"]\n",
    "df_A_PR = df_A_PR[df_A_PR.match_id != \"2020-usopen-1155\"]\n",
    "df_A_PR = df_A_PR.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time=[]\n",
    "for i in range(len(df_A_PR.match_id.unique())):\n",
    "    total_time = np.append(total_time, np.insert(df_A_PR[df_A_PR['match_id'] == df_A_PR.match_id.unique()[i]].Point_lenght_sec.cumsum().values[:-1],0,0))\n",
    "df_A_PR['Total_time']=total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to be swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_shifted=[\n",
    "    ('P1GamesWon','P2GamesWon'),\n",
    "    ('P1Score','P2Score'),\n",
    "    ('P1PointsWon','P2PointsWon'),\n",
    "    ('P1_ServeWidth_B_A','P2_ServeWidth_B_A'),\n",
    "    ('P1_ServeWidth_BC_A','P2_ServeWidth_BC_A'),\n",
    "    ('P1_ServeWidth_BW_A','P2_ServeWidth_BW_A'),\n",
    "    ('P1_ServeWidth_C_A','P2_ServeWidth_C_A'),\n",
    "    ('P1_ServeWidth_W_A','P2_ServeWidth_W_A'),\n",
    "    ('P1_ServeDepth_CTL_A','P2_ServeDepth_CTL_A'),\n",
    "    ('P1_ServeDepth_NCTL_A','P2_ServeDepth_NCTL_A'),\n",
    "    ('P1_ReturnDepth_D_A','P2_ReturnDepth_D_A'),\n",
    "    ('P1_ReturnDepth_ND_A','P2_ReturnDepth_ND_A'),\n",
    "    ('P1AceA','P2AceA'),\n",
    "    ('P1WinnerA','P2WinnerA'),\n",
    "    ('P1DoubleFaultA','P2DoubleFaultA'),\n",
    "    ('P1UnfErrA','P2UnfErrA'),\n",
    "    ('P1NetPointA','P2NetPointA'),\n",
    "    ('P1NetPointWonA','P2NetPointWonA'),\n",
    "    ('P1BreakPointA','P2BreakPointA'),\n",
    "    ('P1BreakPointWonA','P2BreakPointWonA'),\n",
    "    ('P1BreakPointMissedA','P2BreakPointMissedA'),\n",
    "    ('P1DistanceRunA','P1DistanceRunA'),\n",
    "    ('P1SetsWon','P2SetsWon'),\n",
    "    ('player1','player2'),\n",
    "    ('P1NetPoint','P2NetPoint'),\n",
    "    ('P1Rank','P2Rank')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing pointwinenr to binary encoding 0 = p1, 1= p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Server = {1: 0,2: 1}\n",
    "df_A_PR.PointServer = [Server[item] for item in df_A_PR.PointServer]\n",
    "df_A_PR.PointWinner = [Server[item] for item in df_A_PR.PointWinner]\n",
    "df_A_PR.GameWinnerA = [Server[item] for item in df_A_PR.GameWinnerA]\n",
    "df_A_PR.SetWinnerA = [Server[item] for item in df_A_PR.SetWinnerA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface attribute, 0 = US open (Turf), 1 = Wimbeldon grass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface=[]\n",
    "for i in range(len(df_A_PR)):\n",
    "    if df_A_PR.match_id.iloc[i][5] == \"u\":\n",
    "        surface.append(0)\n",
    "    else:\n",
    "        surface.append(1)\n",
    "df_A_PR['Surface']=surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing point number mistakes in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6V6llyDtQN81"
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_A_PR)):\n",
    "    if pd.isna(df_A_PR.iloc[i]['PointNumber']):\n",
    "        df_A_PR['PointNumber'].iloc[i]=df_A_PR['PointNumber'].iloc[i+1]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing NA value for loser rank in a single match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_PR.loc[df_A_PR['match_id'] == \"2020-usopen-1228\", 'loser_rank'] = 501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making rank for p1 and p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_rank = []\n",
    "p2_rank = []\n",
    "for i in range(len(df_A_PR)):\n",
    "    if df_A_PR.player1.iloc[i] == df_A_PR.winner_name.iloc[i]:\n",
    "        p1_rank.append(df_A_PR.winner_rank.iloc[i])\n",
    "        p2_rank.append(df_A_PR.loser_rank.iloc[i])\n",
    "    if df_A_PR.player1.iloc[i] == df_A_PR.loser_name.iloc[i]:\n",
    "        p1_rank.append(df_A_PR.loser_rank.iloc[i])\n",
    "        p2_rank.append(df_A_PR.winner_rank.iloc[i])\n",
    "df_A_PR['P1Rank'] = p1_rank\n",
    "df_A_PR['P2Rank'] = p2_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swapping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_A_PR.copy()\n",
    "for i in range(len(df_A_PR)):\n",
    "    if df_A_PR['PointServer'].loc[i] == 1:\n",
    "        for j in range(len(to_be_shifted)):\n",
    "            df_A_PR.at[i,to_be_shifted[j][0]] = df2[to_be_shifted[j][1]].loc[i]\n",
    "            df_A_PR.at[i,to_be_shifted[j][1]] = df2[to_be_shifted[j][0]].loc[i]\n",
    "        if df_A_PR.PointWinner.loc[i] == 0:\n",
    "            df_A_PR.at[i,\"PointWinner\"] = 1\n",
    "        elif df_A_PR.PointWinner.loc[i] == 1:\n",
    "            df_A_PR.at[i,\"PointWinner\"] = 0\n",
    "            \n",
    "        if df_A_PR.GameWinnerA.loc[i] == 0:\n",
    "            df_A_PR.at[i,\"GameWinnerA\"]=1\n",
    "        elif df_A_PR.GameWinnerA.loc[i] == 1: \n",
    "            df_A_PR.at[i,\"GameWinnerA\"] = 0\n",
    "\n",
    "        if df_A_PR.SetWinnerA.loc[i] == 0:\n",
    "            df_A_PR.at[i,\"SetWinnerA\"]=1\n",
    "        elif df_A_PR.SetWinnerA.loc[i] == 1: \n",
    "            df_A_PR.at[i,\"SetWinnerA\"] = 0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tie=[]\n",
    "for i in range(len(df_A_PR)):\n",
    "    if (df_A_PR.GameNo.iloc[i]>12) and (df_A_PR.Surface.iloc[i]==0):\n",
    "        tie.append(1)\n",
    "    elif (df_A_PR.GameNo.iloc[i] == 25) and (df_A_PR.Surface.iloc[i]==1) and (df_A_PR.year.iloc[i]>2018):\n",
    "        tie.append(1)\n",
    "    elif (df_A_PR.GameNo.iloc[i] > 12) and (df_A_PR.Surface.iloc[i]==1) and (df_A_PR.SetNo.iloc[i] < 5):\n",
    "        tie.append(1)\n",
    "    else:\n",
    "        tie.append(0)\n",
    "df_A_PR['Tiebreak']=tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_A_PR.to_csv(\"FinalData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data point-to-point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "pd.set_option(\"display.max_columns\", None, \"display.max_rows\", 300)\n",
    "\n",
    "df=pd.read_csv('FinalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['match_id','ElapsedTime','SetNo','GameNo','GameWinner','PointWinner','P1Score','P2Score','P1UnfErr','P2UnfErr', 'P1UnfErrA','P2UnfErrA']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Server = {0: 1,1: 2}\n",
    "df.PointServer = [Server[item] for item in df.PointServer]\n",
    "df.PointWinner = [Server[item] for item in df.PointWinner]\n",
    "df.GameWinnerA = [Server[item] for item in df.GameWinnerA]\n",
    "df.SetWinnerA = [Server[item] for item in df.SetWinnerA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hala = {0: 0,1: 1, 2: 1}\n",
    "df.GameWinner = [Hala[item] for item in df.GameWinner]\n",
    "df.SetWinner = [Hala[item] for item in df.SetWinner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['match_id','ElapsedTime','SetNo','GameNo','GameWinner','GameWinnerA','PointWinner','P1Score','P2Score']][:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['match_id','ElapsedTime','SetNo','SetWinner','SetWinnerA','PointWinner','P1Score','P2Score']][60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Kandidat_2_semester')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7a3814ace472c9a6020303c0b948e4dc3352b5fa23366fb0cb9a993484e2f15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
